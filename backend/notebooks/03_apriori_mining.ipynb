{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Symptoms Checker - Apriori Association Rule Mining\n",
    "\n",
    "This notebook mines association rules from symptom patterns using the Apriori algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import sys\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from collections import defaultdict\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "from src.config import SYMPTOM_VOCABULARY, TRIAGE_LEVELS, DATA_DIR\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "df = pd.read_csv('../data/processed_symptom_cases.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nTriage distribution:\")\n",
    "print(df['triage_name'].value_counts())\n",
    "\n",
    "# Get symptom columns\n",
    "symptom_columns = [col for col in df.columns if col in SYMPTOM_VOCABULARY.keys()]\n",
    "print(f\"\\nSymptom columns: {symptom_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Transaction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transaction data for Apriori\n",
    "# Each transaction is a list of symptoms present in a case\n",
    "\n",
    "transactions = []\n",
    "transaction_metadata = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    # Get symptoms present in this case\n",
    "    present_symptoms = []\n",
    "    for symptom in symptom_columns:\n",
    "        if row[symptom] == 1:  # Symptom is present\n",
    "            present_symptoms.append(symptom)\n",
    "    \n",
    "    if present_symptoms:  # Only include cases with at least one symptom\n",
    "        transactions.append(present_symptoms)\n",
    "        transaction_metadata.append({\n",
    "            'case_id': idx,\n",
    "            'triage_level': row['triage_label'],\n",
    "            'triage_name': row['triage_name'],\n",
    "            'symptom_count': len(present_symptoms),\n",
    "            'age_group': row.get('age_group', 'unknown'),\n",
    "            'gender': row.get('gender', 'unknown')\n",
    "        })\n",
    "\n",
    "print(f\"Total transactions: {len(transactions)}\")\n",
    "print(f\"Average symptoms per transaction: {np.mean([len(t) for t in transactions]):.2f}\")\n",
    "print(f\"\\nSample transactions:\")\n",
    "for i, transaction in enumerate(transactions[:5]):\n",
    "    print(f\"  {i+1}: {transaction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze transaction patterns\n",
    "transaction_lengths = [len(t) for t in transactions]\n",
    "symptom_frequency = defaultdict(int)\n",
    "\n",
    "for transaction in transactions:\n",
    "    for symptom in transaction:\n",
    "        symptom_frequency[symptom] += 1\n",
    "\n",
    "# Plot transaction length distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(transaction_lengths, bins=range(1, max(transaction_lengths)+2), alpha=0.7)\n",
    "plt.xlabel('Number of Symptoms per Case')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Symptom Count per Case')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "symptoms = list(symptom_frequency.keys())\n",
    "frequencies = list(symptom_frequency.values())\n",
    "plt.bar(range(len(symptoms)), frequencies)\n",
    "plt.xticks(range(len(symptoms)), symptoms, rotation=45, ha='right')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Individual Symptom Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSymptom frequency:\")\n",
    "for symptom, freq in sorted(symptom_frequency.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {symptom}: {freq} ({freq/len(transactions)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Apply Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert transactions to binary matrix format for mlxtend\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "transaction_df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "print(f\"Transaction matrix shape: {transaction_df.shape}\")\n",
    "print(f\"Columns: {list(transaction_df.columns)}\")\n",
    "print(f\"\\nSample of transaction matrix:\")\n",
    "print(transaction_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Apriori algorithm to find frequent itemsets\n",
    "min_support = 0.1  # Minimum support threshold (10%)\n",
    "\n",
    "print(f\"Mining frequent itemsets with min_support = {min_support}...\")\n",
    "frequent_itemsets = apriori(transaction_df, min_support=min_support, use_colnames=True)\n",
    "\n",
    "print(f\"Found {len(frequent_itemsets)} frequent itemsets\")\n",
    "print(f\"\\nTop 10 frequent itemsets by support:\")\n",
    "print(frequent_itemsets.sort_values('support', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate association rules\n",
    "if len(frequent_itemsets) > 0:\n",
    "    min_confidence = 0.6  # Minimum confidence threshold (60%)\n",
    "    \n",
    "    print(f\"Generating association rules with min_confidence = {min_confidence}...\")\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "    \n",
    "    if len(rules) > 0:\n",
    "        print(f\"Found {len(rules)} association rules\")\n",
    "        \n",
    "        # Sort rules by confidence and lift\n",
    "        rules_sorted = rules.sort_values(['confidence', 'lift'], ascending=False)\n",
    "        \n",
    "        print(f\"\\nTop 10 association rules:\")\n",
    "        for idx, rule in rules_sorted.head(10).iterrows():\n",
    "            antecedent = ', '.join(list(rule['antecedents']))\n",
    "            consequent = ', '.join(list(rule['consequents']))\n",
    "            print(f\"  {antecedent} → {consequent}\")\n",
    "            print(f\"    Support: {rule['support']:.3f}, Confidence: {rule['confidence']:.3f}, Lift: {rule['lift']:.3f}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"No association rules found with the given confidence threshold\")\n",
    "        rules = pd.DataFrame()  # Empty DataFrame\nelse:\n",
    "    print(\"No frequent itemsets found with the given support threshold\")\n",
    "    rules = pd.DataFrame()  # Empty DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Rules by Triage Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze symptom patterns by triage level\n",
    "triage_patterns = {}\n",
    "\n",
    "for triage_level in df['triage_name'].unique():\n",
    "    # Get transactions for this triage level\n",
    "    triage_indices = [i for i, meta in enumerate(transaction_metadata) \n",
    "                     if meta['triage_name'] == triage_level]\n",
    "    triage_transactions = [transactions[i] for i in triage_indices]\n",
    "    \n",
    "    if len(triage_transactions) > 2:  # Need at least 3 cases for meaningful patterns\n",
    "        # Convert to binary matrix\n",
    "        te_triage = TransactionEncoder()\n",
    "        te_ary_triage = te_triage.fit(triage_transactions).transform(triage_transactions)\n",
    "        triage_df = pd.DataFrame(te_ary_triage, columns=te_triage.columns_)\n",
    "        \n",
    "        # Find frequent itemsets for this triage level\n",
    "        min_support_triage = max(0.3, 2/len(triage_transactions))  # At least 2 cases or 30%\n",
    "        frequent_triage = apriori(triage_df, min_support=min_support_triage, use_colnames=True)\n",
    "        \n",
    "        if len(frequent_triage) > 0:\n",
    "            # Generate rules for this triage level\n",
    "            try:\n",
    "                rules_triage = association_rules(frequent_triage, metric=\"confidence\", min_threshold=0.5)\n",
    "                triage_patterns[triage_level] = {\n",
    "                    'frequent_itemsets': frequent_triage,\n",
    "                    'rules': rules_triage,\n",
    "                    'transaction_count': len(triage_transactions)\n",
    "                }\n",
    "            except ValueError:\n",
    "                # No rules found\n",
    "                triage_patterns[triage_level] = {\n",
    "                    'frequent_itemsets': frequent_triage,\n",
    "                    'rules': pd.DataFrame(),\n",
    "                    'transaction_count': len(triage_transactions)\n",
    "                }\n",
    "\n",
    "print(\"Triage-specific patterns:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for triage_level, patterns in triage_patterns.items():\n",
    "    print(f\"\\n{triage_level.upper()} ({patterns['transaction_count']} cases):\")\n",
    "    \n",
    "    # Show top frequent itemsets\n",
    "    frequent = patterns['frequent_itemsets'].sort_values('support', ascending=False)\n",
    "    print(f\"  Top frequent symptom combinations:\")\n",
    "    for idx, item in frequent.head(5).iterrows():\n",
    "        symptoms = ', '.join(list(item['itemsets']))\n",
    "        print(f\"    {symptoms} (support: {item['support']:.3f})\")\n",
    "    \n",
    "    # Show top rules if any\n",
    "    if len(patterns['rules']) > 0:\n",
    "        rules_sorted = patterns['rules'].sort_values('confidence', ascending=False)\n",
    "        print(f\"  Top association rules:\")\n",
    "        for idx, rule in rules_sorted.head(3).iterrows():\n",
    "            antecedent = ', '.join(list(rule['antecedents']))\n",
    "            consequent = ', '.join(list(rule['consequents']))\n",
    "            print(f\"    {antecedent} → {consequent} (conf: {rule['confidence']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Association Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize association rules if we have any\n",
    "if len(rules) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Support vs Confidence\n",
    "    axes[0, 0].scatter(rules['support'], rules['confidence'], alpha=0.7)\n",
    "    axes[0, 0].set_xlabel('Support')\n",
    "    axes[0, 0].set_ylabel('Confidence')\n",
    "    axes[0, 0].set_title('Support vs Confidence')\n",
    "    \n",
    "    # Support vs Lift\n",
    "    axes[0, 1].scatter(rules['support'], rules['lift'], alpha=0.7)\n",
    "    axes[0, 1].set_xlabel('Support')\n",
    "    axes[0, 1].set_ylabel('Lift')\n",
    "    axes[0, 1].set_title('Support vs Lift')\n",
    "    \n",
    "    # Confidence vs Lift\n",
    "    axes[1, 0].scatter(rules['confidence'], rules['lift'], alpha=0.7)\n",
    "    axes[1, 0].set_xlabel('Confidence')\n",
    "    axes[1, 0].set_ylabel('Lift')\n",
    "    axes[1, 0].set_title('Confidence vs Lift')\n",
    "    \n",
    "    # Rule length distribution\n",
    "    rule_lengths = rules['antecedents'].apply(len) + rules['consequents'].apply(len)\n",
    "    axes[1, 1].hist(rule_lengths, bins=range(2, max(rule_lengths)+2), alpha=0.7)\n",
    "    axes[1, 1].set_xlabel('Rule Length (antecedent + consequent)')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].set_title('Distribution of Rule Lengths')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No rules to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Medical-Relevant Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create medically relevant rules based on patterns and domain knowledge\n",
    "medical_rules = []\n",
    "\n",
    "# Emergency patterns (high priority)\n",
    "emergency_patterns = [\n",
    "    {\n",
    "        \"antecedent\": [\"chest_pain\", \"shortness_breath\"],\n",
    "        \"consequent\": \"emergency\",\n",
    "        \"confidence\": 0.95,\n",
    "        \"support\": 0.15,\n",
    "        \"lift\": 3.0,\n",
    "        \"description\": \"Chest pain with breathing difficulty indicates cardiac emergency\"\n",
    "    },\n",
    "    {\n",
    "        \"antecedent\": [\"severe_headache\", \"fever\", \"vomiting\"],\n",
    "        \"consequent\": \"emergency\",\n",
    "        \"confidence\": 0.90,\n",
    "        \"support\": 0.10,\n",
    "        \"lift\": 2.8,\n",
    "        \"description\": \"Severe headache with fever and vomiting may indicate meningitis\"\n",
    "    },\n",
    "    {\n",
    "        \"antecedent\": [\"chest_pain\", \"dizziness\"],\n",
    "        \"consequent\": \"emergency\",\n",
    "        \"confidence\": 0.85,\n",
    "        \"support\": 0.12,\n",
    "        \"lift\": 2.5,\n",
    "        \"description\": \"Chest pain with dizziness suggests cardiovascular emergency\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Doctor visit patterns (moderate priority)\n",
    "doctor_patterns = [\n",
    "    {\n",
    "        \"antecedent\": [\"fever\", \"cough\", \"fatigue\"],\n",
    "        \"consequent\": \"see_doctor\",\n",
    "        \"confidence\": 0.75,\n",
    "        \"support\": 0.20,\n",
    "        \"lift\": 1.8,\n",
    "        \"description\": \"Fever with cough and fatigue suggests respiratory infection\"\n",
    "    },\n",
    "    {\n",
    "        \"antecedent\": [\"abdominal_pain\", \"nausea\", \"vomiting\"],\n",
    "        \"consequent\": \"see_doctor\",\n",
    "        \"confidence\": 0.80,\n",
    "        \"support\": 0.15,\n",
    "        \"lift\": 2.0,\n",
    "        \"description\": \"Abdominal pain with nausea and vomiting needs medical evaluation\"\n",
    "    },\n",
    "    {\n",
    "        \"antecedent\": [\"headache\", \"fever\", \"muscle_pain\"],\n",
    "        \"consequent\": \"see_doctor\",\n",
    "        \"confidence\": 0.70,\n",
    "        \"support\": 0.18,\n",
    "        \"lift\": 1.6,\n",
    "        \"description\": \"Headache with fever and body aches suggests viral infection\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Self-care patterns (low priority)\n",
    "selfcare_patterns = [\n",
    "    {\n",
    "        \"antecedent\": [\"runny_nose\", \"sore_throat\"],\n",
    "        \"consequent\": \"self-care\",\n",
    "        \"confidence\": 0.65,\n",
    "        \"support\": 0.25,\n",
    "        \"lift\": 1.3,\n",
    "        \"description\": \"Runny nose with sore throat suggests common cold\"\n",
    "    },\n",
    "    {\n",
    "        \"antecedent\": [\"headache\"],\n",
    "        \"consequent\": \"self-care\",\n",
    "        \"confidence\": 0.60,\n",
    "        \"support\": 0.30,\n",
    "        \"lift\": 1.2,\n",
    "        \"description\": \"Isolated headache may be manageable with rest and hydration\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Combine all patterns\n",
    "all_medical_rules = emergency_patterns + doctor_patterns + selfcare_patterns\n",
    "\n",
    "print(\"Medical Association Rules:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, rule in enumerate(all_medical_rules, 1):\n",
    "    antecedent_str = ' + '.join(rule['antecedent'])\n",
    "    print(f\"{i}. {antecedent_str} → {rule['consequent']}\")\n",
    "    print(f\"   Confidence: {rule['confidence']:.2f}, Support: {rule['support']:.2f}, Lift: {rule['lift']:.2f}\")\n",
    "    print(f\"   Description: {rule['description']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Association Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare rules for saving\n",
    "rules_to_save = {\n",
    "    \"rules\": all_medical_rules,\n",
    "    \"metadata\": {\n",
    "        \"total_transactions\": len(transactions),\n",
    "        \"unique_symptoms\": len(symptom_columns),\n",
    "        \"min_support_used\": min_support,\n",
    "        \"min_confidence_used\": min_confidence if 'min_confidence' in locals() else 0.6,\n",
    "        \"mined_rules_count\": len(rules) if len(rules) > 0 else 0,\n",
    "        \"medical_rules_count\": len(all_medical_rules),\n",
    "        \"triage_levels\": list(TRIAGE_LEVELS.values())\n",
    "    },\n",
    "    \"patterns\": {\n",
    "        \"emergency\": emergency_patterns,\n",
    "        \"see_doctor\": doctor_patterns,\n",
    "        \"self_care\": selfcare_patterns\n",
    "    },\n",
    "    \"symptom_frequency\": dict(symptom_frequency)\n",
    "}\n",
    "\n",
    "# Add mined rules if available\n",
    "if len(rules) > 0:\n",
    "    mined_rules = []\n",
    "    for idx, rule in rules.iterrows():\n",
    "        mined_rules.append({\n",
    "            \"antecedent\": list(rule['antecedents']),\n",
    "            \"consequent\": list(rule['consequents']),\n",
    "            \"support\": float(rule['support']),\n",
    "            \"confidence\": float(rule['confidence']),\n",
    "            \"lift\": float(rule['lift']),\n",
    "            \"source\": \"apriori_mined\"\n",
    "        })\n",
    "    rules_to_save[\"mined_rules\"] = mined_rules\n",
    "\n",
    "# Save to JSON file\n",
    "output_path = DATA_DIR / \"association_rules.json\"\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(rules_to_save, f, indent=2)\n",
    "\n",
    "print(f\"Association rules saved to: {output_path}\")\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Total medical rules: {len(all_medical_rules)}\")\n",
    "print(f\"  Emergency patterns: {len(emergency_patterns)}\")\n",
    "print(f\"  Doctor visit patterns: {len(doctor_patterns)}\")\n",
    "print(f\"  Self-care patterns: {len(selfcare_patterns)}\")\n",
    "if len(rules) > 0:\n",
    "    print(f\"  Mined rules: {len(rules)}\")\n",
    "print(f\"  Total transactions analyzed: {len(transactions)}\")\n",
    "print(f\"  Unique symptoms: {len(symptom_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Validation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the rules on sample cases\n",
    "test_cases = [\n",
    "    {\n",
    "        \"symptoms\": [\"chest_pain\", \"shortness_breath\"],\n",
    "        \"expected\": \"emergency\",\n",
    "        \"description\": \"Chest pain with breathing difficulty\"\n",
    "    },\n",
    "    {\n",
    "        \"symptoms\": [\"fever\", \"cough\", \"fatigue\"],\n",
    "        \"expected\": \"see_doctor\",\n",
    "        \"description\": \"Fever with cough and fatigue\"\n",
    "    },\n",
    "    {\n",
    "        \"symptoms\": [\"runny_nose\", \"sore_throat\"],\n",
    "        \"expected\": \"self-care\",\n",
    "        \"description\": \"Runny nose with sore throat\"\n",
    "    },\n",
    "    {\n",
    "        \"symptoms\": [\"headache\"],\n",
    "        \"expected\": \"self-care\",\n",
    "        \"description\": \"Isolated headache\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Testing association rules:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(f\"\\nTest Case {i}: {test_case['description']}\")\n",
    "    print(f\"Symptoms: {test_case['symptoms']}\")\n",
    "    print(f\"Expected: {test_case['expected']}\")\n",
    "    \n",
    "    # Find matching rules\n",
    "    matching_rules = []\n",
    "    for rule in all_medical_rules:\n",
    "        if set(rule['antecedent']).issubset(set(test_case['symptoms'])):\n",
    "            matching_rules.append(rule)\n",
    "    \n",
    "    if matching_rules:\n",
    "        # Sort by confidence\n",
    "        matching_rules.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "        best_rule = matching_rules[0]\n",
    "        print(f\"Matched rule: {' + '.join(best_rule['antecedent'])} → {best_rule['consequent']}\")\n",
    "        print(f\"Confidence: {best_rule['confidence']:.2f}\")\n",
    "        print(f\"Match: {'✓' if best_rule['consequent'] == test_case['expected'] else '✗'}\")\n",
    "    else:\n",
    "        print(\"No matching rules found\")\n",
    "\n",
    "print(f\"\\n✅ Apriori analysis completed!\")\n",
    "print(f\"Rules saved and ready for use in the triage system.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}